{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experience 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name**:  Tina Yung-Fang Tu\n",
    "**Time Spent**: 15-20 hrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools as it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please set the path to your data directory here\n",
    "path = './EPI511 2/'\n",
    "\n",
    "# please use the following function (or something like it) to read files\n",
    "def pname(name):\n",
    "    '''Prepend the path to the filename'''\n",
    "    return path + '/' + name\n",
    "\n",
    "def popen(name):\n",
    "    '''Open file in the path'''\n",
    "    return open(pname(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### functions to read in data ##################\n",
    "def read_snp(file):\n",
    "    '''Read a snp file into a pandas dataframe'''\n",
    "    return(pd.read_table(\n",
    "        file,\n",
    "        sep='\\s+', # columns are separated by whitespace\n",
    "        # names of the columns\n",
    "        names=[None, 'chromosome', 'morgans', 'position', 'ref', 'alt'],\n",
    "        index_col=0))\n",
    "\n",
    "SNPs = read_snp(path + 'HapMap3.snp') \n",
    "\n",
    "def get_chr_range(chromosome):\n",
    "    '''Returns the range of positions where SNPs for a chromosome are kept'''\n",
    "    filt = SNPs.query('chromosome=={}'.format(chromosome))\n",
    "    start = SNPs.index.get_loc(filt.iloc[0].name)\n",
    "    stop  = SNPs.index.get_loc(filt.iloc[-1].name) + 1\n",
    "    return(start, stop)\n",
    "\n",
    "def read_geno(file):\n",
    "    '''Reads a geno file into a masked numpy matrix'''\n",
    "    return(np.genfromtxt(\n",
    "        file,               # the file\n",
    "        dtype='uint8',      # read the data in as 1-byte integers\n",
    "        delimiter=1,        # 1-byte width data\n",
    "        missing_values=9,   # 9 indicates missing data\n",
    "        usemask=True        # return a masked array\n",
    "    ))\n",
    "\n",
    "def read_geno_pop_chr(pop, chromosome):\n",
    "    '''Reads a slice of a geno file into a masked numpy matrix'''\n",
    "    f = open(path + pop + '.geno')      # open the file\n",
    "    (start, stop) = get_chr_range(chromosome)\n",
    "    s = it.islice(f, start, stop) # slice the file only keeping SNPs of chr\n",
    "    return read_geno(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Unsupervised clustering without fractional ancestry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Unsupervised clustering without fractional ancestry) Using common HapMap3 SNPs from chromosome 21, apply the EM algorithm to cluster the set of individuals from TSI, JPT and LWK populations into 3 clusters (0, 1, 2), without allowing fractional ancestry and without using allele frequencies from ancestral populations.  (Initialization step: randomly assign ancestry 0 or 1 or 2 to each individual.  M-step: update allele frequencies for populations 0 or 1 or 2 based on cluster assignments and genotypes.  E-step: compute likelihoods for each individual for membership in each cluster and update cluster membership based on highest likelihood.  Note: all genotypes with missing data should be omitted from the computations.).  Report the cluster memberships for each TSI, JPT and LWK individual after each E-step, for the first few E-steps.  How many E-steps does it take for the EM algorithm to reach convergence?  Comment on the correspondence between membership in inferred clusters and membership in the actual populations TSI, JPT and LWK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TSI_geno = read_geno_pop_chr('TSI', 21)\n",
    "JPT_geno = read_geno_pop_chr('JPT', 21)\n",
    "LWK_geno = read_geno_pop_chr('LWK', 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "# Combine the three populations horizontally (SNPs x Individuals)\n",
    "geno_data = np.ma.hstack((TSI_geno, JPT_geno, LWK_geno))\n",
    "\n",
    "# Remove SNPs with any missing values \n",
    "valid_snp_mask = ~np.any(geno_data.mask, axis=1)\n",
    "geno_data = geno_data[valid_snp_mask, :]\n",
    "\n",
    "num_clusters = 3\n",
    "num_individuals = geno_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize cluster assignments randomly\n",
    "num_clusters = 3\n",
    "num_individuals = geno_data.shape[1]\n",
    "cluster_assignments = np.random.randint(0, num_clusters, num_individuals)\n",
    "\n",
    "# Compute allele frequency\n",
    "def compute_allele_frequencies(geno, clusters, num_clusters):\n",
    "    \"\"\"\n",
    "    Compute allele frequencies for each SNP and each cluster.\n",
    "    Returns an array of shape (num_clusters, num_SNPs, 3) containing the frequency \n",
    "    of genotype 0, 1, and 2 for each SNP in each cluster.\n",
    "    \"\"\"\n",
    "    freqs = np.zeros((num_clusters, geno.shape[0], 3))\n",
    "    for k in range(num_clusters):\n",
    "        cluster_indices = np.where(clusters == k)[0]\n",
    "        if len(cluster_indices) > 0:\n",
    "            # Extract the genotypes for individuals in cluster k\n",
    "            cluster_geno = geno[:, cluster_indices]  # Already a masked array, but no missing values remain\n",
    "            for g in range(3):\n",
    "                # np.ma.mean ignores masked values automatically\n",
    "                freq = np.ma.mean(cluster_geno == g, axis=1)\n",
    "                freqs[k, :, g] = freq.filled(0)\n",
    "    return freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1:\n",
      "  TSI cluster assignments: [2 0 2 2 0 0 2 1 2 2 2 2 0 2 1 0 1 1 1 1 1 0 1 1 0 0 1 2 2 2 1 2 1 1 2 1 2\n",
      " 2 0 2 0 2 2 0 0 2 1 0 1 1 1 1 1 0 1 2 2 0 2 2 1 0 1 1 1 1 1 1 1 0 2 1 1 1\n",
      " 1 1 1 2 2 1 2 0 1 0 0 1 2 0]\n",
      "  JPT cluster assignments: [1 0 0 0 0 2 0 0 0 2 0 0 2 2 2 0 2 2 0 2 0 1 2 1 0 2 0 1 0 2 2 0 0 2 2 2 2\n",
      " 0 2 0 2 1 2 0 0 1 2 2 1 2 2 0 2 2 1 1 0 2 2 2 0 0 1 0 2 2 0 2 2 0 0 2 2 2\n",
      " 1 1 1 0 1 0 0 2 1 2 2 0]\n",
      "  LWK cluster assignments: [2 0 2 1 0 0 0 2 1 0 0 0 2 1 1 2 0 1 0 0 2 1 2 2 1 0 0 1 0 1 1 2 1 2 0 0 0\n",
      " 0 2 0 1 1 1 2 0 0 0 2 1 1 0 1 1 2 2 2 2 0 2 1 0 1 1 1 2 2 0 0 2 1 0 2 2 2\n",
      " 1 2 2 2 2 0 0 2 1 0 2 0 0 1 2 2]\n",
      "Iteration 2:\n",
      "  TSI cluster assignments: [1 1 2 2 0 0 1 1 2 2 1 2 1 2 1 0 1 1 1 1 1 1 1 1 1 0 1 2 2 1 1 2 1 1 2 1 2\n",
      " 2 0 2 0 2 2 0 0 2 1 0 1 1 1 1 1 1 1 2 2 0 2 2 1 1 1 1 1 1 1 1 1 0 2 1 1 1\n",
      " 1 1 1 2 2 1 2 1 1 1 0 1 2 1]\n",
      "  JPT cluster assignments: [0 0 0 0 0 2 0 0 0 2 0 0 2 2 2 0 2 2 0 2 0 2 2 2 0 2 0 0 0 2 2 0 0 2 2 2 2\n",
      " 0 2 0 2 0 2 0 0 2 2 2 2 2 2 0 2 2 1 2 0 2 2 2 0 0 2 0 2 2 0 2 2 0 0 2 2 2\n",
      " 2 2 0 0 1 0 0 2 2 2 2 0]\n",
      "  LWK cluster assignments: [2 0 2 1 0 0 0 2 1 0 0 0 2 1 1 2 0 1 0 0 2 1 2 2 1 0 0 1 0 1 1 2 1 2 0 0 0\n",
      " 0 2 0 1 1 1 2 0 0 0 2 1 1 0 1 1 2 2 2 2 0 2 1 0 1 1 1 2 2 0 0 2 1 0 2 2 2\n",
      " 1 2 2 2 2 0 0 2 1 0 2 0 0 1 2 2]\n",
      "Iteration 3:\n",
      "  TSI cluster assignments: [1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 1 1 1 1 1\n",
      " 2 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 2 1 1 1 1 1 1 1 1 1]\n",
      "  JPT cluster assignments: [0 0 0 0 0 2 0 0 0 2 0 0 2 2 2 0 2 2 0 2 0 2 2 2 0 2 0 0 0 2 2 0 0 2 2 2 2\n",
      " 0 2 0 2 0 2 0 0 2 2 2 2 2 2 0 2 2 2 2 0 2 2 2 0 0 2 0 2 2 0 2 2 0 0 2 2 2\n",
      " 2 2 0 0 2 0 0 2 2 2 2 0]\n",
      "  LWK cluster assignments: [2 0 2 1 0 0 0 2 1 0 0 0 2 1 1 2 0 1 0 0 2 1 2 2 1 0 0 1 0 1 1 2 1 2 0 0 0\n",
      " 0 2 0 1 1 1 2 0 0 0 2 1 1 0 1 1 2 2 2 0 0 2 1 0 1 1 1 2 0 0 0 2 1 0 2 2 2\n",
      " 1 2 2 2 2 0 0 2 1 0 2 0 0 1 2 2]\n",
      "Iteration 4:\n",
      "  TSI cluster assignments: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "  JPT cluster assignments: [0 0 0 0 0 2 0 0 2 2 0 2 2 2 2 0 2 2 0 2 0 2 2 2 2 2 2 0 0 2 2 0 0 2 2 2 2\n",
      " 0 2 0 2 0 2 0 0 2 2 2 2 2 2 0 2 2 2 2 0 2 2 2 2 0 2 2 2 2 0 2 2 0 0 2 2 2\n",
      " 2 2 0 2 2 0 0 2 2 2 2 0]\n",
      "  LWK cluster assignments: [2 0 2 0 0 0 0 2 0 0 0 0 0 0 0 2 0 0 0 0 2 1 2 2 0 0 0 0 0 0 0 2 0 2 0 0 0\n",
      " 0 2 0 0 0 0 2 0 0 0 2 0 0 0 0 0 2 2 2 0 0 2 0 0 0 1 0 2 0 0 0 0 0 0 2 2 2\n",
      " 0 2 2 0 2 0 0 2 0 0 2 0 0 0 2 2]\n",
      "Iteration 5:\n",
      "  TSI cluster assignments: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "  JPT cluster assignments: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "  LWK cluster assignments: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Iteration 6:\n",
      "  TSI cluster assignments: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "  JPT cluster assignments: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "  LWK cluster assignments: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Iteration 7:\n",
      "  TSI cluster assignments: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "  JPT cluster assignments: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "  LWK cluster assignments: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Algorithm converged at iteration 7\n"
     ]
    }
   ],
   "source": [
    "max_iter = 10\n",
    "n_TSI = TSI_geno.shape[1]\n",
    "n_JPT = JPT_geno.shape[1]\n",
    "n_LWK = LWK_geno.shape[1]\n",
    "\n",
    "# EM algorithm \n",
    "for iteration in range(max_iter):\n",
    "\n",
    "    allele_freqs = compute_allele_frequencies(geno_data, cluster_assignments, num_clusters)\n",
    "    \n",
    "    new_assignments = np.zeros(num_individuals, dtype=int)\n",
    "    snps = np.arange(geno_data.shape[0])\n",
    "    for i in range(num_individuals):\n",
    "        individual_geno = geno_data[:, i]\n",
    "        likelihoods = np.zeros(num_clusters)\n",
    "        for k in range(num_clusters):\n",
    "            # For each SNP, pick the probability corresponding to the observed genotype\n",
    "            geno_probs = allele_freqs[k, snps, individual_geno.data]\n",
    "            likelihoods[k] = np.sum(np.log(geno_probs + 1e-10))\n",
    "        new_assignments[i] = np.argmax(likelihoods)\n",
    "    \n",
    "    # Report cluster memberships for each population after the E-step\n",
    "    tsi_assignments = new_assignments[:n_TSI]\n",
    "    jpt_assignments = new_assignments[n_TSI : n_TSI + n_JPT]\n",
    "    lwk_assignments = new_assignments[n_TSI + n_JPT : n_TSI + n_JPT + n_LWK]\n",
    "    \n",
    "    print(f\"Iteration {iteration + 1}:\")\n",
    "    print(f\"  TSI cluster assignments: {tsi_assignments}\")\n",
    "    print(f\"  JPT cluster assignments: {jpt_assignments}\")\n",
    "    print(f\"  LWK cluster assignments: {lwk_assignments}\")\n",
    "\n",
    "    # Check convergence\n",
    "    if np.all(new_assignments == cluster_assignments):\n",
    "        print(f\"Algorithm converged at iteration {iteration + 1}\")\n",
    "        break\n",
    "    \n",
    "    # Update assignments for next iteration\n",
    "    cluster_assignments = new_assignments.copy()\n",
    "\n",
    "else:\n",
    "    print(\"Reached maximum iterations without full convergence.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*comments*\n",
    "The algorithm took 7 steps to converge, and it successfully separated 3 populations into 3 clusters, suggesting that the individuals within a population are relatively homogeneous as compared to individuals from another population. The algorithm is effective in assigning individuals to cluster based on allele frequencies. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Supervised clustering with fractional ancestry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Supervised clustering with fractional ancestry) For each of the first 8 ASW samples, estimate their % European ancestry on chromosome 1 by maximizing the log likelihood of generating the ASW genotypes as a linear combination of CEU and YRI ancestral populations.  (Ignore sampling error in CEU and YRI allele frequencies, and ignore the fact that markers are not independent due to LD between markers.  Once again, all genotypes with missing data should be omitted from the computations)  For each of the first 8 ASW samples, repeat the computation without allowing fractional ancestry and indicate which of CEU or YRI ancestry attains the higher log likelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data\n",
    "ASW_geno = read_geno_pop_chr('ASW', 1)\n",
    "CEU_geno = read_geno_pop_chr('CEU', 1)\n",
    "YRI_geno = read_geno_pop_chr('YRI', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = ~(CEU_geno.mask.any(axis=1) | YRI_geno.mask.any(axis=1) | ASW_geno.mask.any(axis=1))\n",
    "\n",
    "# Apply mask to filter SNPs\n",
    "valid_ASW = ASW_geno[valid]\n",
    "valid_CEU = CEU_geno[valid]\n",
    "valid_YRI = YRI_geno[valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the allele frequency for ancestrol population 1 (CEU) and populatiton 2 (YRI)\n",
    "def compute_allele_frequencies(geno_matrix): \n",
    "    return np.mean(geno_matrix, axis=1)/2\n",
    "\n",
    "p_CEU = compute_allele_frequencies(valid_CEU)\n",
    "p_YRI = compute_allele_frequencies(valid_YRI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_log_likelihood(geno, pop1, pop2, alpha):\n",
    "    \n",
    "    p_mixed = alpha * pop1 + (1 - alpha) * pop2  \n",
    "\n",
    "    # Compute probabilities for each genotype\n",
    "    prob_2 = p_mixed ** 2  \n",
    "    prob_1 = 2 * p_mixed * (1 - p_mixed)  \n",
    "    prob_0 = (1 - p_mixed) ** 2  \n",
    "\n",
    "    # Compute log-likelihood\n",
    "    log_likelihood = np.sum(\n",
    "        (geno == 2) * np.log(prob_2) +  \n",
    "        (geno == 1) * np.log(prob_1) +  \n",
    "        (geno == 0) * np.log(prob_0)\n",
    "    )\n",
    "    \n",
    "    return log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_fractional_ancestry(geno, pop1, pop2):\n",
    "    \"\"\"Finds the alpha that maximizes log-likelihood.\"\"\"\n",
    "    alphas = np.linspace(0, 1, 101)  \n",
    "    best_alpha = max(alphas, key=lambda a: compute_log_likelihood(geno, pop1, pop2, a))\n",
    "    return best_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASW Sample 1: Fractional European Ancestry = 0.12\n",
      "ASW Sample 2: Fractional European Ancestry = 0.19\n",
      "ASW Sample 3: Fractional European Ancestry = 0.43\n",
      "ASW Sample 4: Fractional European Ancestry = 0.2\n",
      "ASW Sample 5: Fractional European Ancestry = 0.11\n",
      "ASW Sample 6: Fractional European Ancestry = 0.07\n",
      "ASW Sample 7: Fractional European Ancestry = 0.35000000000000003\n",
      "ASW Sample 8: Fractional European Ancestry = 0.08\n"
     ]
    }
   ],
   "source": [
    "# Analyze first 8 ASW samples\n",
    "for i in range(8):\n",
    "    fractional_ancestry = estimate_fractional_ancestry(valid_ASW[:, i], p_CEU, p_YRI)\n",
    "    print(f\"ASW Sample {i+1}: Fractional European Ancestry = {fractional_ancestry}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASW Sample 1: Ancestry = YRI\n",
      "ASW Sample 2: Ancestry = YRI\n",
      "ASW Sample 3: Ancestry = YRI\n",
      "ASW Sample 4: Ancestry = YRI\n",
      "ASW Sample 5: Ancestry = YRI\n",
      "ASW Sample 6: Ancestry = YRI\n",
      "ASW Sample 7: Ancestry = YRI\n",
      "ASW Sample 8: Ancestry = YRI\n"
     ]
    }
   ],
   "source": [
    "# Compute log-likelihoods for each sample without fractional ancestry \n",
    "log_likelihoods = []\n",
    "for i in range(8):\n",
    "    ll_ceu = compute_log_likelihood(valid_ASW[:, i], p_CEU, p_YRI, alpha=1)  # CEU ancestry\n",
    "    ll_yri = compute_log_likelihood(valid_ASW[:, i], p_CEU, p_YRI, alpha=0)  # YRI ancestry\n",
    "    log_likelihoods.append((\"CEU\" if ll_ceu > ll_yri else \"YRI\"))\n",
    "    print(f\"ASW Sample {i+1}: Ancestry = {log_likelihoods[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*comments* \n",
    "For the ASW population, the fractional European ancestry varies from 0.07 to 0.43, showing an European and African admixture. Yet if we do not allow fractional ancestry, the YRI ancestry attains the higher log likelihood among all the 8 ASW individuals, meaning that the African ancestry contribute the majority of ancestral component in the ASW population. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) Covariances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using common HapMap3 SNPs from chromosome 1, compute and print the 8 x 8 matrix of covariances between normalized genotypes of the first  ASW samples on chromosome 1. Starting with a normalized random vector, use the method of power iteration (normalizing the resulting vector at each iteration) to approximate the top eigenvector of this matrix.  Check that the definition of eigenvector is satisfied.  What is the correlation between this eigenvector and the vector of % European ancestry from Problem 2?     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55983, 8)\n"
     ]
    }
   ],
   "source": [
    "# Normalize the matrix and extract the first 8 individuals\n",
    "ASW_sample = ASW_geno[:, :8]\n",
    "normalized_ASW = (ASW_sample - np.mean(ASW_sample, axis=1, keepdims=True)) / np.std(ASW_sample, axis=1, keepdims=True)\n",
    "print(normalized_ASW.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.97396317 -0.12961659 -0.15345579 -0.13348891 -0.12397316 -0.13924061\n",
      "  -0.14362328 -0.15056483]\n",
      " [-0.12961659  0.93341261 -0.13667759 -0.11511032 -0.13709511 -0.15352397\n",
      "  -0.13494362 -0.1264454 ]\n",
      " [-0.15345579 -0.13667759  1.03763682 -0.15355446 -0.1718135  -0.14956779\n",
      "  -0.12483786 -0.14772983]\n",
      " [-0.13348891 -0.11511032 -0.15355446  0.99407126 -0.12829303 -0.13499524\n",
      "  -0.17323414 -0.15539516]\n",
      " [-0.12397316 -0.13709511 -0.1718135  -0.12829303  0.96079132 -0.12963823\n",
      "  -0.14583642 -0.12414187]\n",
      " [-0.13924061 -0.15352397 -0.14956779 -0.13499524 -0.12963823  0.95244681\n",
      "  -0.13598058 -0.10950039]\n",
      " [-0.14362328 -0.13494362 -0.12483786 -0.17323414 -0.14583642 -0.13598058\n",
      "   0.99572629 -0.13727039]\n",
      " [-0.15056483 -0.1264454  -0.14772983 -0.15539516 -0.12414187 -0.10950039\n",
      "  -0.13727039  0.95104786]]\n"
     ]
    }
   ],
   "source": [
    "# Compute covariance matrix manually (8 × 8)\n",
    "num_SNPs = normalized_ASW.shape[0]\n",
    "num_individuals = normalized_ASW.shape[1]\n",
    "\n",
    "cov_matrix = np.zeros((num_individuals, num_individuals))\n",
    "\n",
    "for i in range(num_individuals):\n",
    "    for j in range(num_individuals):\n",
    "        cov_ij = np.sum(normalized_ASW[:, i] * normalized_ASW[:, j]) / (num_SNPs - 1)  \n",
    "        cov_matrix[i, j] = cov_ij  \n",
    "\n",
    "print(cov_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top Eigenvector Approximation:\n",
      " [ 0.20050247  0.05309918 -0.76177738  0.36888356  0.32840843  0.10370944\n",
      " -0.34530753  0.05248183]\n"
     ]
    }
   ],
   "source": [
    "# Start with a random normalized vector\n",
    "vec = np.random.rand(8)\n",
    "vec /= np.linalg.norm(vec)\n",
    "num_iterations = 1000\n",
    "\n",
    "# Iteration\n",
    "for k in range(num_iterations):\n",
    "    new_vec = np.dot(cov_matrix, vec)  \n",
    "    new_vec /= np.linalg.norm(new_vec)  \n",
    "\n",
    "    vec = new_vec\n",
    "\n",
    "print(\"\\nTop Eigenvector Approximation:\\n\", vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C * v =  [ 0.24259466  0.06424648 -0.92169998  0.44632458  0.39735237  0.12548153\n",
      " -0.41779916  0.06349952]\n",
      "lambda * v =  [ 0.24259466  0.06424648 -0.92169998  0.44632458  0.39735237  0.12548153\n",
      " -0.41779916  0.06349952]\n",
      "The definition of eigenvector is satisfied. \n"
     ]
    }
   ],
   "source": [
    "# Check that the definition of eigenvector is satisfied\n",
    "c_v = np.dot(cov_matrix, vec)\n",
    "lambda_est = np.linalg.norm(c_v) / np.linalg.norm(vec)\n",
    "lambda_v = lambda_est * vec\n",
    "\n",
    "print(\"C * v = \", c_v)\n",
    "print(\"lambda * v = \", lambda_v)\n",
    "\n",
    "if np.allclose(c_v, lambda_v):\n",
    "    print('The definition of eigenvector is satisfied. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between the top eigenvector and % European ancestry: -0.8421089448622563\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Fractional European ancestry \n",
    "european_ancestry = np.array([0.12, 0.19, 0.43, 0.20, 0.11, 0.07, 0.35, 0.08])\n",
    "\n",
    "# Compute the Pearson correlation between the eigenvector and ancestry vector\n",
    "correlation = np.corrcoef(vec, european_ancestry)[0, 1]\n",
    "\n",
    "print(\"Correlation between the top eigenvector and % European ancestry:\", correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*comments*\n",
    "Since the definition of eigenvector is satisfied, we conclude that the computed vector is indeed an eigenvector of the covariance matrix.\n",
    "The high correlation of 0.8421 suggests that the top eigenvector from the covariance matrix is strongly associated with the proportion of European ancestry. In other words, the main axis of genetic variation (captured by the top eigenvector) is reflecting the differences in European admixture among the individuals in this sample population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) Local ancestry inference with ancestral populations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Local ancestry inference with ancestral populations) For each of the first 8 ASW samples, estimate their local ancestry (0, 1 or 2 European copies) at each location on chromosome 1 by splitting chromosome 1 into 10Mb windows and then, for each 10Mb window, applying supervised clustering (using CEU and YRI ancestral populations) within that window in a mode that allows 0%, 50% or 100% ancestry within that window.  Average together the local ancestry estimates to estimate the % European ancestry of each sample on chromosome 1.  How correlated are these estimates to the estimates of the same quantity produced in Problem 2?\n",
    "(Note: any 10Mb windows containing 0 SNPs should be ignored.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNPs in 10Mb: 2272.0451632999484\n"
     ]
    }
   ],
   "source": [
    "# Get SNP positions for a specific chromosome (e.g., chromosome 1)\n",
    "chromosome = 1  \n",
    "start, stop = get_chr_range(chromosome)\n",
    "snp_positions = SNPs.iloc[start:stop]['position'].values\n",
    "\n",
    "# Calculate the average distance between consecutive SNPs\n",
    "snp_differences = np.diff(snp_positions)\n",
    "avg_distance = np.mean(snp_differences)  # average distance between SNPs in base pairs (bp)\n",
    "\n",
    "snp_per_mb = 1_000_000 / avg_distance  # SNPs per 1Mb\n",
    "\n",
    "snp_per_10mb = snp_per_mb * 10  # SNPs per 10Mb\n",
    "print(f\"SNPs in 10Mb: {snp_per_10mb}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting chromosome 1 into 10 Mb windows\n",
    "window_size = int(snp_per_10mb) \n",
    "\n",
    "# Estimate local ancestry \n",
    "def estimate_local_ancestry(geno, pop1_geno, pop2_geno, window_size):\n",
    "    num_samples = geno.shape[1]\n",
    "    num_snps = geno.shape[0]\n",
    "    windows = np.arange(0, num_snps, window_size)  # SNP-based windows\n",
    "    local_ancestry = np.zeros((num_samples, len(windows)))  # Store ancestry per window\n",
    "\n",
    "    for w, start in enumerate(windows):\n",
    "        end = min(start + window_size, num_snps)\n",
    "\n",
    "        geno_window = geno[start:end, :]\n",
    "        pop1_window = pop1_geno[start:end, :]\n",
    "        pop2_window = pop2_geno[start:end, :]\n",
    "\n",
    "        valid_snps = ~np.isnan(geno_window).all(axis=1)\n",
    "        if np.sum(valid_snps) == 0:\n",
    "            continue  # Skip empty windows\n",
    "\n",
    "        geno_window = geno_window[valid_snps, :]\n",
    "        pop1_window = pop1_window[valid_snps, :]\n",
    "        pop2_window = pop2_window[valid_snps, :]\n",
    "\n",
    "        # Compute allele frequencies\n",
    "        p1 = compute_allele_frequencies(pop1_window)  # CEU allele frequency\n",
    "        p2 = compute_allele_frequencies(pop2_window)  # YRI allele frequency\n",
    "\n",
    "        for i in range(num_samples):\n",
    "            sample_geno = geno_window[:, i]\n",
    "\n",
    "            # Compute log-likelihoods \n",
    "            ll_0 = compute_log_likelihood(sample_geno, p1, p2, alpha=0.0)  # 0% European\n",
    "            ll_1 = compute_log_likelihood(sample_geno, p1, p2, alpha=0.5)  # 50% European\n",
    "            ll_2 = compute_log_likelihood(sample_geno, p1, p2, alpha=1.0)  # 100% European\n",
    "\n",
    "            # Assign ancestry based on maximum likelihood\n",
    "            ancestry_state = np.argmax([ll_0, ll_1, ll_2])  \n",
    "            local_ancestry[i, w] = ancestry_state\n",
    "\n",
    "    # Compute final % European ancestry per sample\n",
    "    return np.mean(local_ancestry, axis=1)/2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASW Sample 1: 0.14 % European Ancestry\n",
      "ASW Sample 2: 0.22 % European Ancestry\n",
      "ASW Sample 3: 0.4 % European Ancestry\n",
      "ASW Sample 4: 0.24 % European Ancestry\n",
      "ASW Sample 5: 0.12 % European Ancestry\n",
      "ASW Sample 6: 0.04 % European Ancestry\n",
      "ASW Sample 7: 0.38 % European Ancestry\n",
      "ASW Sample 8: 0.08 % European Ancestry\n",
      "Correlation between European ancestry based on local ancestry and fractional ancestry: 0.9793552469889495\n"
     ]
    }
   ],
   "source": [
    "local_ancestry = estimate_local_ancestry(ASW_sample, CEU_geno, YRI_geno, window_size)\n",
    "for i in range(8):\n",
    "    print(f'ASW Sample {i+1}: {local_ancestry[i]*100} % European Ancestry')\n",
    "\n",
    "# Compute the correlation\n",
    "european_ancestry = np.array([0.12, 0.19, 0.43, 0.20, 0.11, 0.07, 0.35, 0.08])\n",
    "fractional_local_correlation = np.corrcoef(local_ancestry, european_ancestry)[0, 1]\n",
    "\n",
    "print(\"Correlation between European ancestry based on local ancestry and fractional ancestry:\", fractional_local_correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*comments*\n",
    "The high correlation between the calculated European ancestry based on local ancestry and fractional ancestry indicates that supervised clustering for estimating local ancestry is very accurate in reflecting the true European ancestry at each location on chromosome 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (5) Local ancestry inference with ancestral populations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the first 8 ASW samples, estimate their local ancestry at each location on chromosome 1 (analogous to Problem 4) by either (a) restricting to chromosome 1 SNPs with allele frequency difference |pCEU – pYRI| ≥ 0.70, or (b) restricting to a random subset of chromosome 1 SNPs based on the fraction of SNPs retained in (a).  Discuss how results, including correlations to results of Problem 4, change in each case.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_ancestry_restricted(geno, pop1_geno, pop2_geno):\n",
    "    # Determine the number of ASW samples (columns in the genotype matrix)\n",
    "    num_samples = geno.shape[1]\n",
    "    \n",
    "    # Compute allele frequencies for the reference populations (CEU and YRI)\n",
    "    p_CEU_all = compute_allele_frequencies(pop1_geno)\n",
    "    p_YRI_all = compute_allele_frequencies(pop2_geno)\n",
    "    \n",
    "    valid_mask = ~np.isnan(p_CEU_all) & ~np.isnan(p_YRI_all) \n",
    "    combined_mask = valid_mask & (np.abs(p_CEU_all - p_YRI_all) >= 0.70) \n",
    "    \n",
    "    # Apply the mask to restrict the genotype matrices to only these SNPs\n",
    "    geno_filtered = geno[combined_mask, :]\n",
    "    pop1_geno_filtered = pop1_geno[combined_mask, :]\n",
    "    pop2_geno_filtered = pop2_geno[combined_mask, :]\n",
    "    \n",
    "    # Count the number of SNPs remaining after filtering\n",
    "    num_significant = geno_filtered.shape[0]\n",
    "    print(\"Number of significant SNPs:\", num_significant)\n",
    "    \n",
    "    # Initialize an array to store the ancestry state (0, 1, or 2 European copies) for each sample at each SNP\n",
    "    ancestry_states = np.zeros((num_samples, num_significant))\n",
    "    \n",
    "    # Loop over each filtered SNP\n",
    "    for s in range(num_significant):\n",
    "        p1 = np.mean(pop1_geno_filtered[s, :]) / 2  # CEU allele frequency at SNP s\n",
    "        p2 = np.mean(pop2_geno_filtered[s, :]) / 2  # YRI allele frequency at SNP s\n",
    "        \n",
    "        # Loop over each ASW sample to estimate ancestry at SNP s\n",
    "        for i in range(num_samples):\n",
    "            geno_val = np.ma.filled(geno_filtered[s, i], -1)\n",
    "            p1_arr = np.array([p1])\n",
    "            p2_arr = np.array([p2])\n",
    "            \n",
    "            # Compute log-likelihoods for three ancestry states:\n",
    "            ll_0 = compute_log_likelihood(geno_val, p1_arr, p2_arr, alpha=0.0)\n",
    "            ll_1 = compute_log_likelihood(geno_val, p1_arr, p2_arr, alpha=0.5)\n",
    "            ll_2 = compute_log_likelihood(geno_val, p1_arr, p2_arr, alpha=1.0)\n",
    "            \n",
    "            # Choose the state with the highest likelihood.\n",
    "            state = np.argmax([ll_0, ll_1, ll_2])\n",
    "            ancestry_states[i, s] = state\n",
    "    \n",
    "    # Average the ancestry state across all significant SNPs for each sample.\n",
    "    final_ancestry = np.mean(ancestry_states, axis=1) / 2    \n",
    "    return final_ancestry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of significant SNPs: 217\n",
      "ASW Sample 1: 0.16589861751152074 % European Ancestry based on SNPs with allele frequency difference ≥ 0.70\n",
      "ASW Sample 2: 0.23271889400921658 % European Ancestry based on SNPs with allele frequency difference ≥ 0.70\n",
      "ASW Sample 3: 0.44930875576036866 % European Ancestry based on SNPs with allele frequency difference ≥ 0.70\n",
      "ASW Sample 4: 0.27419354838709675 % European Ancestry based on SNPs with allele frequency difference ≥ 0.70\n",
      "ASW Sample 5: 0.2465437788018433 % European Ancestry based on SNPs with allele frequency difference ≥ 0.70\n",
      "ASW Sample 6: 0.2119815668202765 % European Ancestry based on SNPs with allele frequency difference ≥ 0.70\n",
      "ASW Sample 7: 0.39631336405529954 % European Ancestry based on SNPs with allele frequency difference ≥ 0.70\n",
      "ASW Sample 8: 0.15207373271889402 % European Ancestry based on SNPs with allele frequency difference ≥ 0.70\n",
      "Correlation between calculated local ancestry using all SNPs and using significant SNPs: 0.9100183019830573\n"
     ]
    }
   ],
   "source": [
    "new_local_ancestry_values = local_ancestry_restricted(ASW_sample, CEU_geno, YRI_geno)\n",
    "for i in range(8):\n",
    "    print(f'ASW Sample {i+1}: {new_local_ancestry_values[i]} % European Ancestry based on SNPs with allele frequency difference ≥ 0.70')\n",
    "\n",
    "# Compute the correlation\n",
    "fractional_correlation = np.corrcoef(local_ancestry, new_local_ancestry_values)[0, 1]\n",
    "print(\"Correlation between calculated local ancestry using all SNPs and using significant SNPs:\", fractional_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_ancestry_random(geno, pop1_geno, pop2_geno, num_significant):\n",
    "    # Determine the number of ASW samples (columns in the genotype matrix)\n",
    "    num_samples = geno.shape[1]\n",
    "    \n",
    "    # Randomly select 217 SNPs from chromosome 1 \n",
    "    snp_indices = np.random.choice(geno.shape[0], num_significant, replace=False)\n",
    "    \n",
    "    # Filter the genotype matrices based on the randomly selected SNPs\n",
    "    geno_filtered = geno[snp_indices, :]\n",
    "    pop1_geno_filtered = pop1_geno[snp_indices, :]\n",
    "    pop2_geno_filtered = pop2_geno[snp_indices, :]\n",
    "    \n",
    "    # Initialize an array to store the ancestry state \n",
    "    ancestry_states = np.zeros((num_samples, num_significant))\n",
    "    \n",
    "    # Loop over each selected SNP\n",
    "    for s in range(num_significant):\n",
    "        p1 = np.mean(pop1_geno_filtered[s, :]) / 2  \n",
    "        p2 = np.mean(pop2_geno_filtered[s, :]) / 2  \n",
    "        \n",
    "        # Loop over each ASW sample \n",
    "        for i in range(num_samples):\n",
    "            geno_val = np.ma.filled(geno_filtered[s, i], -1)\n",
    "            p1_arr = np.array([p1])\n",
    "            p2_arr = np.array([p2])\n",
    "            \n",
    "            # Compute log-likelihoods for three ancestry states:\n",
    "            ll_0 = compute_log_likelihood(geno_val, p1_arr, p2_arr, alpha=0.0)\n",
    "            ll_1 = compute_log_likelihood(geno_val, p1_arr, p2_arr, alpha=0.5)\n",
    "            ll_2 = compute_log_likelihood(geno_val, p1_arr, p2_arr, alpha=1.0)\n",
    "            \n",
    "            # Choose the state with the highest likelihood\n",
    "            state = np.argmax([ll_0, ll_1, ll_2])\n",
    "            ancestry_states[i, s] = state\n",
    "    \n",
    "    # Average the ancestry state across all randomly selected SNPs for each sample\n",
    "    local_ancestry_estimates = np.mean(ancestry_states, axis=1) / 2  \n",
    "    return local_ancestry_estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASW Sample 1: 0.47465437788018433 % European Ancestry based on random 217 SNPs\n",
      "ASW Sample 2: 0.4608294930875576 % European Ancestry based on random 217 SNPs\n",
      "ASW Sample 3: 0.45852534562211983 % European Ancestry based on random 217 SNPs\n",
      "ASW Sample 4: 0.49078341013824883 % European Ancestry based on random 217 SNPs\n",
      "ASW Sample 5: 0.4447004608294931 % European Ancestry based on random 217 SNPs\n",
      "ASW Sample 6: 0.4078341013824885 % European Ancestry based on random 217 SNPs\n",
      "ASW Sample 7: 0.4470046082949309 % European Ancestry based on random 217 SNPs\n",
      "ASW Sample 8: 0.4423963133640553 % European Ancestry based on random 217 SNPs\n",
      "Correlation between calculated local ancestry using all SNPs and using random SNPs: 0.4157118515847857\n"
     ]
    }
   ],
   "source": [
    "# Number of significant SNPs\n",
    "num_significant = 217\n",
    "np.random.seed(11)\n",
    "\n",
    "random_local_ancestry_values = local_ancestry_random(ASW_sample, CEU_geno, YRI_geno, num_significant=217)\n",
    "for i in range(8):\n",
    "    print(f'ASW Sample {i+1}: {random_local_ancestry_values[i]} % European Ancestry based on random 217 SNPs')\n",
    "\n",
    "# Compute the correlation\n",
    "random_correlation = np.corrcoef(local_ancestry, random_local_ancestry_values)[0, 1]\n",
    "print(\"Correlation between calculated local ancestry using all SNPs and using random SNPs:\", random_correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*comments*\n",
    "When using the SNPs with allele frequency difference |pCEU – pYRI| ≥ 0.70, we found that the estimated European ancestrty is very accurate. Also, the correlation of 0.91 between the calculated local ancestry using all SNPs and the significant SNPs is very high, indicating that the significant SNPs capture much of the information we need to infer local ancestry. However, because fewer markers are used, there are still slight deviations from the full SNP estimates. \n",
    "When randomly selecting 217 SNPs from chromosome 1, the estimated European ancestry is relatively unstable based on the SNPs we choose. The correlation between the calculated ancestry using all SNPs and the random SNPs is also much lower (0.42), suggesting that the random SNPs do not correlate as strongly with the full set of SNPs, therefore would not be a good proxy for local ancestry inference. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
