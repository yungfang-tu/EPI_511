{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experience 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name**:  Tina Tu\n",
    "**Time Spent**: 15 hrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:**\n",
    "- `import random` for simulations  \n",
    "- Use `np.random.seed(301404)` as the random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools as it\n",
    "from scipy.stats import chi2\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Simulate a set of 1,000 SNPs with minor allele frequencies (in the entire population) randomly sampled to lie between 5% and 50% (uniform distribution).  Simulate genotypes for 200 (diploid) individuals at these SNPs.  How many SNPs are polymorphic in the first 50 individuals? How many SNPs are polymorphic in the first 100 individuals? How many SNPs are polymorphic in all 200 individuals? \n",
    "(b) Simulate a set of 1,000 SNPs with minor allele frequencies (in the entire population) randomly sampled to lie between 0.1% and 50% (uniform distribution).  Simulate genotypes for 200 (diploid) individuals at these SNPs.  How many SNPs are polymorphic in the first 50 individuals? How many SNPs are polymorphic in the first 100 individuals? How many SNPs are polymorphic in all 200 individuals? \n",
    "(c) Simulate a set of 1,000 SNPs with minor allele frequencies (in the entire population) randomly sampled to lie between 0.1% and 50% (with probability density inversely proportional to the minor allele frequency, e.g. 1% is 10x more likely than 10%; use rejection sampling as in Experience 5 Problem 4).  Simulate genotypes for 200 (diploid) individuals at these SNPs.  How many SNPs are polymorphic in the first 50 individuals? How many SNPs are polymorphic in the first 100 individuals? How many SNPs are polymorphic in all 200 individuals?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polymorphic SNPs in first 50 individuals: 1000\n",
      "Polymorphic SNPs in first 100 individuals: 1000\n",
      "Polymorphic SNPs in all 200 individuals: 1000\n"
     ]
    }
   ],
   "source": [
    "# Set seed for reproducibility\n",
    "np.random.seed(301404)\n",
    "\n",
    "# Parameters\n",
    "num_snps = 1000\n",
    "num_individuals = 200\n",
    "\n",
    "# Step 1: Simulate minor allele frequencies between 0.05 and 0.5\n",
    "mafs = np.random.uniform(0.05, 0.5, size=num_snps)\n",
    "\n",
    "# Step 2: Simulate genotypes (each individual has 2 alleles per SNP)\n",
    "genotypes = np.array([\n",
    "    np.random.binomial(2, maf, size=num_individuals)\n",
    "    for maf in mafs\n",
    "])\n",
    "\n",
    "# Function to count polymorphic SNPs in a subset of individuals\n",
    "def count_polymorphic_snps(genotype_matrix):\n",
    "    return np.sum([len(np.unique(snp)) > 1 for snp in genotype_matrix])\n",
    "\n",
    "# Step 3: Count polymorphic SNPs in subsets\n",
    "poly_50 = count_polymorphic_snps(genotypes[:, :50])\n",
    "poly_100 = count_polymorphic_snps(genotypes[:, :100])\n",
    "poly_200 = count_polymorphic_snps(genotypes[:, :200])\n",
    "\n",
    "print(f\"Polymorphic SNPs in first 50 individuals: {poly_50}\")\n",
    "print(f\"Polymorphic SNPs in first 100 individuals: {poly_100}\")\n",
    "print(f\"Polymorphic SNPs in all 200 individuals: {poly_200}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polymorphic SNPs in first 50 individuals: 989\n",
      "Polymorphic SNPs in first 100 individuals: 995\n",
      "Polymorphic SNPs in all 200 individuals: 1000\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(301404)\n",
    "\n",
    "# Step 1: Simulate minor allele frequencies between 0.001 and 0.5\n",
    "maf2 = np.random.uniform(0.001, 0.5, size=num_snps)\n",
    "\n",
    "# Step 2: Simulate genotypes (each individual has 2 alleles per SNP)\n",
    "genotypes_2 = np.array([\n",
    "    np.random.binomial(2, maf, size=num_individuals)\n",
    "    for maf in maf2\n",
    "])\n",
    "\n",
    "# Step 3: Count polymorphic SNPs in subsets\n",
    "poly_50 = count_polymorphic_snps(genotypes_2[:, :50])\n",
    "poly_100 = count_polymorphic_snps(genotypes_2[:, :100])\n",
    "poly_200 = count_polymorphic_snps(genotypes_2[:, :200])\n",
    "\n",
    "print(f\"Polymorphic SNPs in first 50 individuals: {poly_50}\")\n",
    "print(f\"Polymorphic SNPs in first 100 individuals: {poly_100}\")\n",
    "print(f\"Polymorphic SNPs in all 200 individuals: {poly_200}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polymorphic SNPs in first 50 individuals: 706\n",
      "Polymorphic SNPs in first 100 individuals: 802\n",
      "Polymorphic SNPs in all 200 individuals: 877\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(301404)\n",
    "\n",
    "# Step 1: Rejection sampling to get MAFs ∝ 1/maf\n",
    "def sample_inverse_maf(n, lower, upper, max_attempts):\n",
    "    mafs = []\n",
    "    attempts = 0\n",
    "    while len(mafs) < n and attempts < max_attempts:\n",
    "        x = np.random.uniform(lower, upper)\n",
    "        y = np.random.uniform(0, 1 / lower) \n",
    "        if y <= 1 / x:\n",
    "            mafs.append(x)\n",
    "        attempts += 1\n",
    "    return np.array(mafs)\n",
    "\n",
    "maf3 = sample_inverse_maf(num_snps, 0.001, 0.5, 100000)\n",
    "\n",
    "# Step 2: Simulate genotypes\n",
    "genotypes_3 = np.array([\n",
    "    np.random.binomial(2, maf, size=num_individuals)\n",
    "    for maf in maf3\n",
    "])\n",
    "\n",
    "poly_50 = count_polymorphic_snps(genotypes_3[:, :50])\n",
    "poly_100 = count_polymorphic_snps(genotypes_3[:, :100])\n",
    "poly_200 = count_polymorphic_snps(genotypes_3[:, :200])\n",
    "\n",
    "print(f\"Polymorphic SNPs in first 50 individuals: {poly_50}\")\n",
    "print(f\"Polymorphic SNPs in first 100 individuals: {poly_100}\")\n",
    "print(f\"Polymorphic SNPs in all 200 individuals: {poly_200}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*comments*\n",
    "\n",
    "In the first simulation (MAF 5%–50%), all SNPs are relatively common, so they remain polymorphic even in small samples. In the second scenario (MAF 0.1%–50%), some SNPs are very rare, leading to a few SNPs becoming monomorphic (i.e., only one allele observed) in smaller samples. In the third simulation, where rare variants are even more enriched, a substantial number of SNPs are monomorphic. Overall, SNPs with higher minor allele frequencies (common variants) are almost always polymorphic, meaning both alleles are consistently observed even in small samples (e.g., 50 individuals). In contrast, rare variants (low MAF) are often monomorphic in small samples and require much larger sample sizes to be observed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate a set of 100 SNPs with minor allele frequencies (in the entire population) randomly sampled to lie between 0.1% and 1% (uniform distribution).  Simulate genotypes for 10,000 individuals at these SNPs.  (Note that the real HapMap3 data set used in this course contains only common SNPs.)  Assign all 100 SNPs as causal SNPs.  Simulate quantitative phenotypes for the 10,000 individuals by assuming that causal SNPs have effect size per normalized genotype = ±0.01, where normalized genotype is defined using the MAF in the entire population (not the sample MAF in the finite sample); the probability of having a positive effect sign (i.e. +0.01 rather than −0.01) varies linearly from 0.5 for MAF=1% SNPs to 1 for MAF=0.1% SNPs; and normally distributed environmental noise (unrelated to the 100 SNPs) with variance 0.99 is added to each phenotype.  \n",
    "(a) Viewing the 100 SNPs as lying in a single simulated gene, use the Fixed threshold burden test, at various choices of MAF threshold (for the MAF in the finite sample), to test the gene for association to phenotype. Which MAF threshold produces the most significant test statistic?\n",
    "(b) use the Madsen & Browning Weighted test to test the gene for association to phenotype.  Are results more significant than the Fixed threshold test?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random effect sizes\n",
    "def sample_normal(n, std):\n",
    "    samples = []\n",
    "    while len(samples) < n:\n",
    "        x = np.random.uniform(-10, 10)\n",
    "        accept_prob = np.exp(-x**2 / 2)  \n",
    "        if np.random.uniform(0, 1) < accept_prob:\n",
    "            samples.append(x * std)\n",
    "    return np.array(samples)\n",
    "\n",
    "def sample_maf(genotypes):\n",
    "    return np.mean(genotypes, axis=1) / 2\n",
    "\n",
    "def burden_t_stat(burden, phenotype):\n",
    "    if len(burden) != len(phenotype) or len(burden) == 0:\n",
    "        return 0.0\n",
    "    r = np.corrcoef(burden, phenotype)[0, 1]\n",
    "    return 0.0 if np.isnan(r) else len(burden) * r**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(301404)\n",
    "\n",
    "num_snps = 100\n",
    "num_individuals = 10000\n",
    "\n",
    "# Sample MAFs uniformly between 0.001 and 0.01\n",
    "mafs = np.random.uniform(0.001, 0.01, size=num_snps)\n",
    "\n",
    "# Simulate genotypes (0, 1, 2 minor alleles)\n",
    "genotypes = np.array([\n",
    "    np.random.binomial(2, maf, size=num_individuals)\n",
    "    for maf in mafs\n",
    "]) \n",
    "\n",
    "# Normalized genotype\n",
    "norm_genotypes = np.array([\n",
    "    (genotypes[j] - 2 * mafs[j]) / np.sqrt(2 * mafs[j] * (1 - mafs[j]))\n",
    "    for j in range(num_snps)\n",
    "])\n",
    "\n",
    "# Step 4: Assign effect sizes: ±0.01 with P(+) from 0.5 (at MAF=1%) to 1 (at MAF=0.1%)\n",
    "prob_positive = 0.5 + (0.01 - mafs) / 0.009 * 0.5\n",
    "effect_signs = np.where(np.random.uniform(size=num_snps) < prob_positive, 1, -1)\n",
    "effect_sizes = 0.01 * effect_signs  \n",
    "\n",
    "# Step 5: Simulate phenotypes\n",
    "genetic_component = np.dot(effect_sizes, norm_genotypes)  \n",
    "environmental_effect = np.random.normal(0, np.sqrt(0.99), size=num_individuals)\n",
    "phenotypes = genetic_component + environmental_effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold 0.0005: no SNPs below MAF threshold.\n",
      "Threshold 0.0010: no SNPs below MAF threshold.\n",
      "Threshold 0.0050: 46 SNPs selected, chi-square statistic = 37.1334\n",
      "Threshold 0.0100: 99 SNPs selected, chi-square statistic = 9.8027\n",
      "Threshold 0.0200: 100 SNPs selected, chi-square statistic = 13.4206\n",
      "\n",
      "Most significant MAF threshold: 0.005\n"
     ]
    }
   ],
   "source": [
    "# Define candidate MAF thresholds\n",
    "thresholds = [0.0005, 0.001, 0.005, 0.01, 0.02] \n",
    "chi_stats = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    mafs_sample = sample_maf(genotypes)\n",
    "    selected_snps = genotypes[mafs_sample < threshold]\n",
    "\n",
    "    num_selected_snps = selected_snps.shape[0]  # Number of SNPs selected\n",
    "\n",
    "    if num_selected_snps > 0:\n",
    "        burden_scores = np.sum(selected_snps, axis=0, dtype=np.float64)\n",
    "\n",
    "        # Get both t_stat and chi-square equivalent\n",
    "        chi_equiv = burden_t_stat(burden_scores, phenotypes)\n",
    "        \n",
    "        print(f\"Threshold {threshold:.4f}: {num_selected_snps} SNPs selected, chi-square statistic = {chi_equiv:.4f}\")\n",
    "        chi_stats.append(chi_equiv)\n",
    "    else:\n",
    "        chi_stats.append(np.nan)\n",
    "        print(f\"Threshold {threshold:.4f}: no SNPs below MAF threshold.\")\n",
    "\n",
    "# Find most significant\n",
    "best_threshold = thresholds[np.nanargmax(chi_stats)]\n",
    "print(f\"\\nMost significant MAF threshold: {best_threshold}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Burden Test: chi-square statistic (weighted) = 23.173854355756475\n"
     ]
    }
   ],
   "source": [
    "weights = 1 / np.sqrt(mafs * (1 - mafs) )\n",
    "\n",
    "# Step 3: compute weighted burden score\n",
    "weighted_genotypes = weights[:, np.newaxis] * genotypes  \n",
    "burden_scores_weighted = np.sum(weighted_genotypes, axis=0)\n",
    "\n",
    "# Step 4: run burden test\n",
    "chi_weighted = burden_t_stat(burden_scores_weighted, phenotypes)\n",
    "\n",
    "print(f\"Weighted Burden Test: chi-square statistic (weighted) = {chi_weighted}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*comments*\n",
    "\n",
    "Based on the results, the 0.005 MAF threshold performed best with the most significant test statistic in the fixed threshold burden test. When the threshold was larger than 0.005, more SNPs were included. Hence, we were mixing SNPs with very different effect size signs, and collapsed them would weaken the association because the effects were cancelled out. When the threshold was smaller than 0.05, we included fewer SNPs, so the signal strength decreased because the burden test lost power. \n",
    "\n",
    "The Madsen & Browning weighted burden test weighted SNPs inversely proportional to their MAF. In this simulation, SNPs rarer than ~0.5% MAF tend to have more consistently positive effects, so giving more emphasis to very rare SNPs would theoretically yield a higher test statistic. In this case, the number is slightly lower  than the best fixed threshold (0.005) but higher than 0.01 and 0.02 thresholds. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a population with 1,000 haploid individuals.  Perform forward simulations in which the allele frequency of a neutral new mutation in the population (initial allele frequency = 0.1%) is simulated for 100 subsequent generations (in each generation, sample each individual’s haploid genotype using the allele frequency from the previous generation).  Repeat 1,000 times.\n",
    "(a) What proportion of the time does the new mutation become relatively common (MAF ≥ 1%)?\n",
    "(b) Perform simulations with a selection coefficient of s = −0.01 (in each generation, sample each individual’s haploid genotype from the previous generation’s haploid individuals such that individuals with the mutation are 1+s times as likely to be sampled).  Repeat 1,000 times.  \n",
    "What proportion of the time does the new mutation become relatively common (MAF ≥ 1%)?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion where allele (neutral mutation) becomes common (MAF ≥ 1%): 0.016\n",
      "Proportion where allele (negative mutation) becomes common (MAF ≥ 1%): 0.007\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(301404)\n",
    "\n",
    "# Parameters\n",
    "N = 1000\n",
    "generations = 100\n",
    "af = 0.001\n",
    "\n",
    "# Neutral\n",
    "def simulate_one_run(N, generations, af):\n",
    "    freq = af\n",
    "    for _ in range(generations):\n",
    "        # Sample number of derived alleles in next generation\n",
    "        count = np.random.binomial(N, freq)\n",
    "        freq = count / N\n",
    "    return freq\n",
    "\n",
    "# Run simulation 1,000 times\n",
    "n_runs = 1000\n",
    "final_freqs = [simulate_one_run(N, generations, af) for _ in range(n_runs)]\n",
    "\n",
    "# Count how many runs end with freq >= 0.01 (1%)\n",
    "num_common = sum(f >= 0.01 for f in final_freqs)\n",
    "proportion = num_common / n_runs\n",
    "\n",
    "print(f\"Proportion where allele (neutral mutation) becomes common (MAF ≥ 1%): {proportion}\")\n",
    "\n",
    "# Negative \n",
    "np.random.seed(301404)\n",
    "s = -0.01   \n",
    "\n",
    "def selected_forward(N, generations, af, s):\n",
    "    freq = af\n",
    "    for _ in range(generations):\n",
    "        n_mut = int(freq * N)\n",
    "        n_wt = N - n_mut\n",
    "\n",
    "        # Compute total fitness weights\n",
    "        total_fitness = n_mut * (1 + s) + n_wt\n",
    "        prob_mut = (n_mut * (1 + s)) / total_fitness\n",
    "\n",
    "        # Sample next generation\n",
    "        n_mut_next = np.random.binomial(N, prob_mut)\n",
    "        freq = n_mut_next / N\n",
    "\n",
    "        if freq == 0:\n",
    "            break \n",
    "\n",
    "    return freq\n",
    "\n",
    "# Run 1000 simulations\n",
    "final_freqs = [selected_forward(N, generations, af, s) for _ in range(n_runs)]\n",
    "\n",
    "# Count how many runs ended with MAF ≥ 1%\n",
    "num_neg = sum(f >= threshold for f in final_freqs)\n",
    "proportion_neg = num_neg / n_runs\n",
    "\n",
    "print(f\"Proportion where allele (negative mutation) becomes common (MAF ≥ 1%): {proportion_neg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*comments*\n",
    "\n",
    "If the new mutation is neutral, MAF is only influenced by genetic drift (random fluctuations). Thus, ~1.9% of neutral mutations managed to drift up to ≥1% MAF. However, when the selection coefficient of s = −0.01, the new variant is less likely to drift up (negative selection consistently pushes allele frequencies down). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Consider a set of 100 linked SNPs in the 112 CEU individuals. (For example, you could choose the first 100 SNPs). Simulate quantitative phenotypes for CEU individuals by assuming that all 100 SNPs are causal, and effect sizes per normalized genotype are sampled from a normal distribution with variance 0.015 for even SNPs (0, 2, …) and a normal distribution with variance 0.005 for odd SNPs (1, 3, …).  What is the true functional enrichment of even SNPs as compared to all 100 SNPs?  Does the (average χ2 association statistic – 1) for even SNPs as compared to all 100 SNPs accurately reflect the true functional enrichment?  Why or why not? \n",
    "(b) Repeat the simulation in (a) using a set of 100 unlinked SNPs in the 112 CEU individuals.  (For example, you could choose every 125th SNP of the first 12,500 SNPs). Does the (average χ2 association statistic – 1) for even SNPs as compared to all 100 SNPs accurately reflect the true functional enrichment?  Why or why not?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please set the path to your data directory here\n",
    "path = \"./EPI511/\"\n",
    "\n",
    "# please use the following function (or something like it) to read files\n",
    "def pname(name):\n",
    "    '''Prepend the path to the filename'''\n",
    "    return path + '/' + name\n",
    "\n",
    "def popen(name):\n",
    "    '''Open file in the path'''\n",
    "    return open(pname(name))\n",
    "\n",
    "def read_geno(file):\n",
    "    '''Reads a geno file into a masked numpy matrix'''\n",
    "    return(np.genfromtxt(\n",
    "        file,               # the file\n",
    "        dtype='uint8',      # read the data in as 1-byte integers\n",
    "        delimiter=1,        # 1-byte width data\n",
    "        missing_values=9,   # 9 indicates missing data\n",
    "        usemask=True        # return a masked array\n",
    "    ))\n",
    "\n",
    "# Reads a slice of a geno file into a numpy matrix\n",
    "def read_geno_pop_islice(pop, *args):\n",
    "    f = popen(pop + '.geno') \n",
    "    s = it.islice(f, *args)  \n",
    "    return read_geno(s)\n",
    "\n",
    "# Calculate allele frequency\n",
    "def calculate_af(geno):\n",
    "    return np.ma.mean(geno, axis=1).filled(-1) / 2\n",
    "\n",
    "# Normalize geno matrix\n",
    "def normalize_geno(geno, p=None):\n",
    "    if p is None: p = calculate_af(geno)\n",
    "    return ( (geno - (2 * p)[:, np.newaxis]) / np.sqrt(2 * p * (1 - p))[:, np.newaxis]).filled(0)\n",
    "\n",
    "# Armitage trend test\n",
    "def armitage_trend_test(genotype, phenotype):\n",
    "    if np.ma.isMaskedArray(genotype):\n",
    "        valid = ~genotype.mask\n",
    "    else:\n",
    "        valid = np.ones_like(genotype, dtype=bool)\n",
    "\n",
    "    valid_genotype = genotype[valid]\n",
    "    valid_phenotype = phenotype[valid] \n",
    "\n",
    "    if len(valid_genotype) == 0:\n",
    "        return np.nan\n",
    "\n",
    "    r = np.corrcoef(valid_genotype, valid_phenotype)[0, 1]\n",
    "    if np.isnan(r):\n",
    "        return np.nan\n",
    "\n",
    "    N = len(valid_genotype)\n",
    "    return N * r**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True functional enrichment (even SNPs/all SNPs): 1.5687145221945467\n",
      "Enrichment estimate from χ²: 1.1212114010523564\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(301404)\n",
    "CEU_geno = read_geno_pop_islice('CEU', 0, 100, 1)\n",
    "num_snps, num_individuals = CEU_geno.shape\n",
    "\n",
    "# Normalize genotypes (per SNP)\n",
    "CEU_geno_norm = normalize_geno(CEU_geno)\n",
    "\n",
    "# Simulate effect sizes\n",
    "effect_sizes = np.zeros(num_snps)\n",
    "even_idx = np.arange(0, num_snps, 2)\n",
    "odd_idx = np.arange(1, num_snps, 2)\n",
    "\n",
    "effect_sizes[even_idx] = sample_normal(len(even_idx), np.sqrt(0.015))\n",
    "effect_sizes[odd_idx] = sample_normal(len(odd_idx), np.sqrt(0.005))\n",
    "\n",
    "# Simulate phenotype\n",
    "phenotype = np.dot(effect_sizes, CEU_geno_norm)  \n",
    "genetic_variance = np.var(phenotype)\n",
    "\n",
    "# True functional enrichment\n",
    "even_genetic_var = np.var(np.dot(effect_sizes[even_idx], CEU_geno_norm[even_idx, :]))\n",
    "heritability_even= even_genetic_var / genetic_variance\n",
    "enrichment = heritability_even / (len(even_idx) / num_snps)\n",
    "print(f\"True functional enrichment (even SNPs/all SNPs): {enrichment}\")\n",
    "\n",
    "# Step 5: Association test using Armitage trend test\n",
    "chi2_stats = []\n",
    "for i in range(num_snps):\n",
    "    x = CEU_geno_norm[i]\n",
    "    chi2 = armitage_trend_test(x, phenotype)\n",
    "    chi2_stats.append(chi2)\n",
    "\n",
    "chi2_stats = np.array(chi2_stats)\n",
    "\n",
    "# Step 6: Compare average χ² - 1\n",
    "mean_chi2_all = np.mean(chi2_stats)\n",
    "mean_chi2_even = np.mean(chi2_stats[even_idx])\n",
    "enrichment_chi2 = (mean_chi2_even - 1) / (mean_chi2_all - 1)\n",
    "\n",
    "print(f\"Enrichment estimate from χ²: {enrichment_chi2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True functional enrichment (even SNPs/all SNPs): 1.6832496877899932\n",
      "Enrichment estimate from χ²: 1.6473640500638613\n"
     ]
    }
   ],
   "source": [
    "CEU_geno_2 = read_geno_pop_islice('CEU', 0, 12500, 125)\n",
    "num_snps, num_individuals = CEU_geno.shape\n",
    "\n",
    "# Step 1: Normalize genotypes (per SNP)\n",
    "CEU_norm_2 = normalize_geno(CEU_geno_2)\n",
    "\n",
    "# Step 2: Simulate phenotype\n",
    "phenotype_2 = np.dot(effect_sizes, CEU_norm_2)  \n",
    "genetic_var_2 = np.var(phenotype_2)\n",
    "\n",
    "# Step 4: True functional enrichment\n",
    "even_var_2 = np.var(np.dot(effect_sizes[even_idx], CEU_norm_2[even_idx, :]))\n",
    "\n",
    "heritability_even= even_var_2 / genetic_var_2\n",
    "enrichment = heritability_even / (len(even_idx) / num_snps)\n",
    "print(f\"True functional enrichment (even SNPs/all SNPs): {enrichment}\")\n",
    "\n",
    "chi2_unlinked = []\n",
    "for i in range(num_snps):\n",
    "    x = CEU_norm_2[i]\n",
    "    chi2 = armitage_trend_test(x, phenotype_2)\n",
    "    chi2_unlinked.append(chi2)\n",
    "\n",
    "chi2_unlinked = np.array(chi2_unlinked)\n",
    "\n",
    "# Compare average χ² - 1\n",
    "mean_chi2_all = np.mean(chi2_unlinked)\n",
    "mean_chi2_even = np.mean(chi2_unlinked[even_idx])\n",
    "enrichment_unlinked = (mean_chi2_even - 1) / (mean_chi2_all - 1)\n",
    "\n",
    "print(f\"Enrichment estimate from χ²: {enrichment_unlinked}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*comments*\n",
    "\n",
    "The linked SNPs show a true functional enrichment of approximately 1.568, but the enrichment estimated from χ² statistics is lower (~1.121). This discrepancy likely arises from the small sample size (n = 112 CEU individuals) and residual linkage disequilibrium (LD) between SNPs. When SNPs are in LD, their χ² statistics reflect not only their own effects but also the effects of neighboring variants, causing a dilution of the true causal signal. Consequently, LD leads to an underestimation of enrichment when relying on χ²-based estimates compared to variance-based enrichment.\n",
    "\n",
    "For unlinked SNPs, the true enrichment was estimated at 1.683, closely matching the enrichment estimated from χ² (~1.647), suggesting that unlinked SNPs provide more accurate enrichment estimation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a set of 100 linked SNPs in the 112 CEU individuals.  (For example, you could choose the first 100 SNPs).  Compute the LD score (sum of r2 across the set of 100 SNPs) of each of the 100 SNPs.  Label the 50 SNPs with highest LD score as “high-LD” SNPs, and label the 50 SNPs with lowest LD score as “low-LD” SNPs.  Simulate quantitative phenotypes for CEU individuals by assuming that all 100 SNPs are causal, and effect sizes per normalized genotype are sampled from a normal distribution with variance 0.015 for low-LD SNPs and a normal distribution with variance 0.005 for high-LD SNPs. What is the true heritability enrichment of low-LD SNPs as compared to all 100 SNPs?  Does the (average χ2 association statistic – 1) for low-LD SNPs as compared to all 100 SNPs accurately reflect the true heritability enrichment?  Why or why not? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_r2(snp1, snp2):\n",
    "    gA = snp1.astype(float)\n",
    "    gB = snp2.astype(float)\n",
    "    \n",
    "    if np.std(gA) == 0 or np.std(gB) == 0:\n",
    "        return np.nan\n",
    "\n",
    "    # Mean genotype\n",
    "    gA_mean = np.mean(gA)\n",
    "    gB_mean = np.mean(gB)\n",
    "\n",
    "    var_a = np.var(gA)\n",
    "    var_b = np.var(gB)\n",
    "\n",
    "    # Compute r^2\n",
    "    numerator = (np.mean(gA * gB) - gA_mean * gB_mean) ** 2\n",
    "    denominator = var_a * var_b\n",
    "    \n",
    "    if denominator == 0:\n",
    "        return np.nan\n",
    "    return numerator / denominator\n",
    "\n",
    "\n",
    "def compute_all_ld_scores(geno_data):\n",
    "    num_snps = geno_data.shape[0]\n",
    "    ld_scores = np.zeros(num_snps)\n",
    "\n",
    "    for snp_idx in range(num_snps):\n",
    "        # Compute LD score for each SNP\n",
    "        target_snp = geno_data[snp_idx, :]\n",
    "        \n",
    "        r_squared_values = np.array([\n",
    "            compute_r2(target_snp, geno_data[i, :]) for i in range(num_snps)])\n",
    "        \n",
    "        # Set self-correlation to 1\n",
    "        r_squared_values[snp_idx] = 1.0\n",
    "        \n",
    "        # Sum all r^2 values\n",
    "        ld_scores[snp_idx] = np.nansum(r_squared_values)\n",
    "\n",
    "    return ld_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True functional enrichment for low LD SNPs: 1.5375945766566217\n",
      "Enrichment estimate from χ²: 1.2567029028812229\n"
     ]
    }
   ],
   "source": [
    "ld_scores = compute_all_ld_scores(CEU_geno_norm)  \n",
    "sorted_indices = np.argsort(ld_scores)  \n",
    "\n",
    "# Label low-LD and high-LD SNPs\n",
    "low_ld_indices = sorted_indices[:50]    # 50 SNPs with lowest LD scores\n",
    "high_ld_indices = sorted_indices[-50:]  # 50 SNPs with highest LD scores\n",
    "\n",
    "np.random.seed(301404)\n",
    "\n",
    "# Initialize effect sizes\n",
    "effect_sizes = np.zeros(num_snps)\n",
    "\n",
    "effect_sizes[low_ld_indices] = sample_normal(len(low_ld_indices), np.sqrt(0.015))\n",
    "effect_sizes[high_ld_indices] = sample_normal(len(high_ld_indices), np.sqrt(0.005))\n",
    "\n",
    "# Simulate phenotype (pure genetic effect)\n",
    "phenotype_LD = np.dot(effect_sizes, CEU_geno_norm) \n",
    "\n",
    "genetic_var_LD = np.var(phenotype_LD)\n",
    "\n",
    "low_ld_var = np.var(np.dot(effect_sizes[low_ld_indices], CEU_geno_norm[low_ld_indices, :]))\n",
    "\n",
    "heritability_LD = low_ld_var / genetic_var_LD\n",
    "\n",
    "enrichment = heritability_LD / (len(low_ld_indices) / num_snps)\n",
    "print(f\"True functional enrichment for low LD SNPs: {enrichment}\")\n",
    "\n",
    "chi2_LD = []\n",
    "for i in range(num_snps):\n",
    "    x = CEU_geno_norm[i]\n",
    "    chi2 = armitage_trend_test(x, phenotype_LD)\n",
    "    chi2_LD.append(chi2)\n",
    "\n",
    "chi2_LD = np.array(chi2_LD)\n",
    "\n",
    "# Compare average χ² - 1\n",
    "mean_chi2_all = np.mean(chi2_LD)\n",
    "mean_chi2_low_ld = np.mean(chi2_LD[low_ld_indices])\n",
    "enrichment_LD = (mean_chi2_low_ld - 1) / (mean_chi2_all - 1)\n",
    "\n",
    "print(f\"Enrichment estimate from χ²: {enrichment_LD}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*comments*\n",
    "\n",
    "The low-LD SNPs exhibit a true functional enrichment of approximately 1.538, but the enrichment estimated from χ² statistics is slightly lower (~1.257). Given the small sample size (112 individuals), the χ² statistics are expected to be noisy. Moreover, despite separating SNPs into high- and low-LD groups, there may still be residual LD within the low-LD set. Additionally, the variance around the effect sizes (~0.015) contributes to random variability. As a result, the enrichment estimate based on χ² is slightly attenuated relative to the true value. Nevertheless, the enrichment calculated from χ² here is closer to the enrichment calculated from χ² in Q4. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
